{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e7331-3e3e-47d1-a8d8-e141cee9b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6953f0-2eef-45c0-801c-fc6348bedb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_X = 128\n",
    "SIZE_Y = 128\n",
    "n_classes = 1\n",
    "num_images = len(glob.glob(\"images_train_dataset/*.jpg\"))\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c7f36-0207-49da-aa0d-53473360440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = glob.glob(\"images_train_dataset/*.jpg\")\n",
    "image_names.sort()\n",
    "image_names_subset = image_names[0:num_images]\n",
    "images = [cv2.imread(mask, 0) for mask in image_names_subset]\n",
    "image_dataset = np.array(images)\n",
    "image_dataset = np.expand_dims(image_dataset, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359f341-7c82-43fa-8b8f-f87a0cacfbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_names = glob.glob(\"images_masks_dataset/*.tiff\")\n",
    "mask_names.sort()\n",
    "mask_names_subset = mask_names[0:num_images]\n",
    "masks = [cv2.imread(mask, 0) for mask in mask_names_subset]\n",
    "mask_dataset = np.array(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e56933a1-086d-463a-8707-2cf5bdcfc0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape:  (54, 768, 768, 1)\n",
      "Mask data shape:  (54, 768, 768)\n",
      "Max pixel value in image:  1.0\n",
      "Labels in the mask:  [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Image data shape: \", image_dataset.shape)\n",
    "print(\"Mask data shape: \", mask_dataset.shape)\n",
    "print(\"Max pixel value in image: \", image_dataset.max())\n",
    "print(\"Labels in the mask: \", np.unique(mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc9b47f-664f-45c8-a19f-d0a88c380f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "n, h, w = mask_dataset.shape\n",
    "mask_dataset_reshaped = mask_dataset.reshape(-1, 1)\n",
    "mask_dataset_reshaped_encoded = labelEncoder.fit_transform(mask_dataset_reshaped)\n",
    "mask_dataset_encoded = mask_dataset_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(mask_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4bf6f57-af11-435a-b6a6-67ae740fe67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 768, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "mask_dataset_encoded = np.expand_dims(mask_dataset_encoded, axis = 3)\n",
    "print(mask_dataset_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b31c11-1c2c-4686-bfd9-13910cc7f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7f35f8-3b4b-427c-832b-e52c8e93d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset_encoded, test_size= 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0926f5-ca34-4136-87e0-002f269026e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_masks_ship = to_categorical(y_train, num_classes = n_classes - 1)\n",
    "y_train_ship = train_masks_ship\n",
    "\n",
    "test_masks_ship = to_categorical(y_test, num_classes = n_classes - 1)\n",
    "y_test_ship = test_masks_ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c0b8b6-de31-4438-8bdd-b7c24c5f3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2,2))(x)\n",
    "    return x,p\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x= conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    b1 = conv_block(p4, 1024)\n",
    "    \n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    if n_classes == 1:\n",
    "        activation = \"sigmoid\"\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)\n",
    "    print(activation)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"U-net\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "482e00ef-69e0-4626-9aef-a519f9098f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "544c6464-8991-4b5a-bc39-da7489999c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "Model: \"U-net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 768, 768, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 768, 768, 64  640         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 768, 768, 64  256        ['conv2d_38[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 768, 768, 64  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 768, 768, 64  36928       ['activation_36[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 768, 768, 64  256        ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 768, 768, 64  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 384, 384, 64  0          ['activation_37[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 384, 384, 12  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 384, 384, 12  512        ['conv2d_40[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 384, 384, 12  0           ['batch_normalization_38[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 384, 384, 12  147584      ['activation_38[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 384, 384, 12  512        ['conv2d_41[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 384, 384, 12  0           ['batch_normalization_39[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 192, 192, 12  0          ['activation_39[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 192, 192, 25  295168      ['max_pooling2d_9[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 192, 192, 25  1024       ['conv2d_42[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 192, 192, 25  0           ['batch_normalization_40[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 192, 192, 25  590080      ['activation_40[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 192, 192, 25  1024       ['conv2d_43[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 192, 192, 25  0           ['batch_normalization_41[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 96, 96, 256)  0          ['activation_41[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 96, 96, 512)  1180160     ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 96, 96, 512)  2048       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 96, 96, 512)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 96, 96, 512)  2359808     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 96, 96, 512)  2048       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 96, 96, 512)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 48, 48, 512)  0          ['activation_43[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 48, 48, 1024  4719616     ['max_pooling2d_11[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 48, 48, 1024  4096       ['conv2d_46[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 48, 48, 1024  0           ['batch_normalization_44[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 48, 48, 1024  9438208     ['activation_44[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 48, 48, 1024  4096       ['conv2d_47[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 48, 48, 1024  0           ['batch_normalization_45[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 96, 96, 512)  2097664    ['activation_45[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 96, 96, 1024  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                )                                 'activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 96, 96, 512)  4719104     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 96, 96, 512)  2048       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 96, 96, 512)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 96, 96, 512)  2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 96, 96, 512)  2048       ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 96, 96, 512)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 192, 192, 25  524544     ['activation_47[0][0]']          \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 192, 192, 51  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                2)                                'activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 192, 192, 25  1179904     ['concatenate_9[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 192, 192, 25  1024       ['conv2d_50[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 192, 192, 25  0           ['batch_normalization_48[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 192, 192, 25  590080      ['activation_48[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 192, 192, 25  1024       ['conv2d_51[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 192, 192, 25  0           ['batch_normalization_49[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 384, 384, 12  131200     ['activation_49[0][0]']          \n",
      " nspose)                        8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 384, 384, 25  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                6)                                'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 384, 384, 12  295040      ['concatenate_10[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 384, 384, 12  512        ['conv2d_52[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 384, 384, 12  0           ['batch_normalization_50[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 384, 384, 12  147584      ['activation_50[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 384, 384, 12  512        ['conv2d_53[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 384, 384, 12  0           ['batch_normalization_51[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 768, 768, 64  32832      ['activation_51[0][0]']          \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 768, 768, 12  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                8)                                'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 768, 768, 64  73792       ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 768, 768, 64  256        ['conv2d_54[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 768, 768, 64  0           ['batch_normalization_52[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 768, 768, 64  36928       ['activation_52[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 768, 768, 64  256        ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 768, 768, 64  0           ['batch_normalization_53[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 768, 768, 1)  65          ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,054,145\n",
      "Trainable params: 31,042,369\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_unet(input_shape, n_classes = 1)\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1efa0ee4-136f-4d8b-b381-757dc2d8b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[16,768,768,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node U-net/batch_normalization_36/FusedBatchNormV3\n (defined at f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:589)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8914]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node U-net/batch_normalization_36/FusedBatchNormV3:\nIn[0] U-net/conv2d_38/BiasAdd (defined at f:\\python\\lib\\site-packages\\keras\\layers\\convolutional.py:264)\t\nIn[1] U-net/batch_normalization_36/ReadVariableOp:\t\nIn[2] U-net/batch_normalization_36/ReadVariableOp_1:\t\nIn[3] U-net/batch_normalization_36/FusedBatchNormV3/ReadVariableOp:\t\nIn[4] U-net/batch_normalization_36/FusedBatchNormV3/ReadVariableOp_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"f:\\python\\lib\\runpy.py\", line 192, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"f:\\python\\lib\\runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\paul\\AppData\\Local\\Temp/ipykernel_14948/2449028395.py\", line 1, in <module>\n>>>     history = model.fit(X_train, y_train_ship,\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n>>>     outputs = self._fused_batch_norm(inputs, training=training)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n>>>     output, mean, variance = control_flow_util.smart_cond(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n>>>     return tf.__internal__.smart_cond.smart_cond(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n>>>     return tf.compat.v1.nn.fused_batch_norm(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14948/2449028395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(X_train, y_train_ship,\n\u001b[0m\u001b[0;32m      2\u001b[0m                    \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_ship\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[16,768,768,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node U-net/batch_normalization_36/FusedBatchNormV3\n (defined at f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:589)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_8914]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node U-net/batch_normalization_36/FusedBatchNormV3:\nIn[0] U-net/conv2d_38/BiasAdd (defined at f:\\python\\lib\\site-packages\\keras\\layers\\convolutional.py:264)\t\nIn[1] U-net/batch_normalization_36/ReadVariableOp:\t\nIn[2] U-net/batch_normalization_36/ReadVariableOp_1:\t\nIn[3] U-net/batch_normalization_36/FusedBatchNormV3/ReadVariableOp:\t\nIn[4] U-net/batch_normalization_36/FusedBatchNormV3/ReadVariableOp_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"f:\\python\\lib\\runpy.py\", line 192, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"f:\\python\\lib\\runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"f:\\python\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\paul\\AppData\\Local\\Temp/ipykernel_14948/2449028395.py\", line 1, in <module>\n>>>     history = model.fit(X_train, y_train_ship,\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n>>>     outputs = self._fused_batch_norm(inputs, training=training)\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n>>>     output, mean, variance = control_flow_util.smart_cond(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n>>>     return tf.__internal__.smart_cond.smart_cond(\n>>> \n>>>   File \"f:\\python\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n>>>     return tf.compat.v1.nn.fused_batch_norm(\n>>> "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_ship,\n",
    "                   batch_size = 16,\n",
    "                   verbose = 1,\n",
    "                   epochs = 100,\n",
    "                   validation_data = (X_test, y_test_ship),\n",
    "                   shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59757d4e-e352-4917-a3b2-1fe31d49385c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
